# ML_DL_Genomics

Top machine learning algorithms:

ðŸ”¢ <b>Supervised Learning Algorithms</b><br><br>
<b>1. Linear Regression:</b>Predicts a continuous target variable assuming a linear relationship between inputs and output.

<b>2. Logistic Regression:</b> Used for binary classification; estimates the probability of a class using a logistic (sigmoid) function.

<b>3. Decision Trees:</b> Uses a tree-like structure to split data based on feature values for classification or regression tasks.

<b>4.Random Forest:</b> An ensemble of decision trees that improves accuracy and reduces overfitting by averaging multiple tree outputs.

<b>5. Support Vector Machines (SVM):</b> Finds the optimal hyperplane to separate classes in the feature space, maximizing the margin between them.

<b>6. K-Nearest Neighbors (KNN)</b>: Predicts based on the majority label (or average) of the k nearest data points in the training set.

<b>7.Naive Bayes:</b> A probabilistic classifier based on Bayes' Theorem, assuming feature independence.

<b>8. Gradient Boosting Machines (e.g., XGBoost, LightGBM):</b> Sequentially builds weak learners (usually trees) to correct errors of previous models using boosting.

ðŸ“Š <b>Unsupervised Learning Algorithms:</b><br><br>
<b>1.K-Means Clustering:</b> Partitions data into K clusters based on feature similarity by minimizing intra-cluster variance.

<b>2.Hierarchical Clustering:</b> Builds a tree of clusters (dendrogram), suitable for visualizing nested grouping in data like gene expression.

ðŸ§  <b>Neural Networks:</b><br><br>
<b>1.Artificial Neural Networks (ANN):</b> Brain-inspired networks for general prediction tasks.

<b>2.Convolutional Neural Networks (CNN):</b> Specialized neural networks for processing grid-like data, especially images.

